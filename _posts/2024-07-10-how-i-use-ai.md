---
title: "How I Use AI"
tags: [AI, LLMs]
---

It's the middle of 2024 and unless you live under a rock you've certainly encountered the trend of "AI" infiltrating virtually every piece of software we use. This isn't necessarily a bad thing, but there are some AI features that are far more valuable than others. Here's how I use AI in my day-to-day life.

## Writing

I *never* use AI to help me write. Writing is challenging, but the challenge is what makes it worth it. Think of writing like exercise for the brain. Your brain, like other parts of your body, needs exercise to stay healthy. I enjoy flexing those writing muscles - and you should too!

And I write quite a bit. The nature of working in a mostly-remote company means that a lot of our work is done asynchronously via written communication. I can see how it's tempting to use AI to help you write, but I think it's overall more harmful than helpful. Formulating thoughts to the point you can write them down and communicate them clearly is an incredibly valuable process and clearly elevates the quality of your work. Writing well makes you really think about what you want to say and forces you to string together sometimes disjointed thoughts into something concrete.

## Research

I do use AI (primarily ChatGPT, but also Gemini) for general Q&A and research, and I think this is one thing it excels at.

You *do* need to be cautious when using AI tools for research. After all LLMs **cannot actually reason** and simply use mathematical probability to generate one token at a time. LLMs are notorious for "hallucinating" facts precisely because of this. LLMs with better training data will be better at reproducing accurate information, but the generated text can only be as accurate as the training data. And guess what? There's a lot of inaccurate information out there on the internet.

I like to treat text generated by LLMs like I do other untrusted information on the internet. Trust but verify. Use it as a jumping-off point for future, more in-depth research. I wouldn't use it to answer a question that I need to 100% verify is correct, but I think it can be an incredibly useful tool to help generate ideas.

## Coding

I do use ChatGPT/Gemini semi-frequently with coding and other technical questions. This could be something as simple as "what does this library do?" to "write a cron schedule that runs every Friday at 2AM".

I have begun experimenting with GitHub Copilot when writing code, but I don't use it all that much yet. I feel like when I try to use it I am constantly trying to write code according to what the AI is expecting. For some reason it prevents me from getting into the "flow state" and it doesn't encourage me to approach problems holistically.

## Other Generative AI

I don't currently use any kind of image, video, or audio generative AI. I don't have a need to, and I personally prefer art made by actual people.

## chambers.io/ai

It's important to set personal limits on how we approach and use AI tools as they becomes more prevalent throughout our society. I have created a new permanent page on my website (https://chambers.io/ai) that I will keep updated (inspired by the legendary [Derek Sivers](https://sive.rs/ai)) with how I personally use AI to *add value to my life* in a sustainable way.
