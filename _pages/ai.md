---
layout: page
author_profile: true
title: "AI Usage"
permalink: /ai
last_modified_at: 2025-03-17
---

It's important to set personal limits on how we approach and use AI tools as they becomes more prevalent throughout our society.
I have created this [permanent page](ai.md), inspired by [Dever Sivers](https://sive.rs/ai) and [Damola Morenikeji](https://www.bydamo.la/p/ai-manifesto).
I will keep it updated with how I personally use AI to *add value to my life* in a sustainable way.

## Writing

I *almost never* use AI to help me write.
Writing is challenging, but the challenge is what makes it worth it.
Think of writing like exercise for the brain.
Your brain, like other parts of your body, needs exercise to stay healthy.
I enjoy flexing those writing muscles - and you should too!

And I write quite a bit.
The nature of working in a mostly-remote company means that a lot of our work is done asynchronously via written communication.
I can see how it's tempting to use AI to help you write, but I think it's overall more harmful than helpful.
Formulating thoughts to the point you can write them down and communicate them clearly is an incredibly valuable process and clearly elevates the quality of your work.
Writing well makes you really think about what you want to say and forces you to string together sometimes disjointed thoughts into something concrete.

The one exception to this rule is autocomplete text messages or emails.
Ones that are transactional in nature - ones that don't require me to flex those creative writing muscles.

## Research

I do use AI (primarily ChatGPT, but also Gemini) for general Q&A and research, and I think this is one thing it excels at.

My Pixel 9 Pro that I purchased in December 2024 included a free one year subscription to Google's Gemini Advanced AI, and it's been a really great conversational research "partner".
The conversational style voice synthesis is really, scary good.

You *do* need to be cautious when using AI tools for research.
After all LLMs **cannot actually reason** and simply use mathematical probability to generate one token at a time.
LLMs are notorious for "hallucinating" facts precisely because of this.
LLMs with better training data will be better at reproducing accurate information, but the generated text can only be as accurate as the training data.
And guess what?
There's a lot of inaccurate information out there on the internet.

I like to treat text generated by LLMs like I do other untrusted information on the internet.
Trust but verify.
Use it as a jumping-off point for future, more in-depth research.
I wouldn't use it to answer a question that I need to 100% verify is correct, but I think it can be an incredibly useful tool to help generate ideas.

## Software Development

I do use ChatGPT/Gemini semi-frequently with coding and other technical questions.
This could be something as simple as "what does this library do?" to "write a cron schedule that runs every Friday at 2AM".

At work I use GitHub Copilot to help write code. It's pretty good at boilerplate code generation and for helping act as an "advanced autocomplete" tool that will fill in details I alreayd have in my head.
I use the [Zed](https://zed.dev/) editor mainly and have recently begun experimenting with their AI-powereod inline code completion tool.
It lets you choose your own LLM backend amongst many they support, so I can use my GitHub Copilot license for work stuff but I use a Google Gemini API key for personal stuff.

## Other Generative AI

I don't currently use any kind of image, video, or audio generative AI.
I don't have a need to, and I personally prefer art made by actual people.

## Things I am Interested In

Traditional text-to-speech tools are pretty bad.
I really would like to be able to send an article to one of these advanced voice AI tools and have it read it to me like a podcast/audiobook.
